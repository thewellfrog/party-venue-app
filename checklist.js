#!/usr/bin/env node

const { createClient } = require("@supabase/supabase-js");
require("dotenv").config({ path: ".env.local" });

const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

// Checklist items with validation functions
const checklist = [
  {
    step: "1. Environment Variables",
    description: "Check that all required environment variables are loaded",
    async check() {
      const required = [
        "NEXT_PUBLIC_SUPABASE_URL",
        "NEXT_PUBLIC_SUPABASE_ANON_KEY",
        "SUPABASE_SERVICE_ROLE_KEY",
        "OPENAI_API_KEY",
      ];

      const missing = required.filter((key) => !process.env[key]);

      if (missing.length === 0) {
        return { status: "âœ…", message: "All environment variables are set" };
      } else {
        return { status: "âŒ", message: `Missing: ${missing.join(", ")}` };
      }
    },
  },

  {
    step: "2. Database Connection",
    description: "Verify Supabase database connection",
    async check() {
      try {
        const { data, error } = await supabaseAdmin
          .from("scraping_queue")
          .select("count")
          .limit(1);

        if (error) {
          return { status: "âŒ", message: `Database error: ${error.message}` };
        }

        return { status: "âœ…", message: "Database connection successful" };
      } catch (error) {
        return { status: "âŒ", message: `Connection failed: ${error.message}` };
      }
    },
  },

  {
    step: "3. Database Schema",
    description: "Check that required tables exist",
    async check() {
      try {
        const tables = ["scraping_queue", "venues", "packages"];
        const results = [];

        for (const table of tables) {
          const { data, error } = await supabaseAdmin
            .from(table)
            .select("count")
            .limit(1);

          if (error) {
            results.push(`${table}: âŒ`);
          } else {
            results.push(`${table}: âœ…`);
          }
        }

        const failed = results.filter((r) => r.includes("âŒ"));
        if (failed.length === 0) {
          return { status: "âœ…", message: "All required tables exist" };
        } else {
          return {
            status: "âŒ",
            message: `Table issues: ${failed.join(", ")}`,
          };
        }
      } catch (error) {
        return {
          status: "âŒ",
          message: `Schema check failed: ${error.message}`,
        };
      }
    },
  },

  {
    step: "4. URLs in Queue",
    description: "Check if there are URLs ready for scraping",
    async check() {
      try {
        const { data, error } = await supabaseAdmin
          .from("scraping_queue")
          .select("*")
          .eq("status", "pending");

        if (error) {
          return {
            status: "âŒ",
            message: `Queue check failed: ${error.message}`,
          };
        }

        if (!data || data.length === 0) {
          return {
            status: "âš ï¸",
            message: "No pending URLs found - need to add URLs",
          };
        }

        return {
          status: "âœ…",
          message: `${data.length} URLs ready for scraping`,
        };
      } catch (error) {
        return { status: "âŒ", message: `Queue check error: ${error.message}` };
      }
    },
  },

  {
    step: "5. Scraped Data",
    description: "Check if any URLs have been successfully scraped",
    async check() {
      try {
        const { data, error } = await supabaseAdmin
          .from("scraping_queue")
          .select("*")
          .eq("status", "completed")
          .not("scraped_data", "is", null);

        if (error) {
          return {
            status: "âŒ",
            message: `Scraped data check failed: ${error.message}`,
          };
        }

        if (!data || data.length === 0) {
          return {
            status: "âš ï¸",
            message: "No scraped data found - need to run scraping",
          };
        }

        return {
          status: "âœ…",
          message: `${data.length} URLs have scraped data`,
        };
      } catch (error) {
        return {
          status: "âŒ",
          message: `Scraped data check error: ${error.message}`,
        };
      }
    },
  },

  {
    step: "6. OpenAI API",
    description: "Test OpenAI API connection and key",
    async check() {
      try {
        const { OpenAI } = await import("openai");
        const openai = new OpenAI({
          apiKey: process.env.OPENAI_API_KEY,
        });

        // Simple test API call
        const completion = await openai.chat.completions.create({
          model: "gpt-4o-mini",
          messages: [
            {
              role: "user",
              content:
                "Hello, just testing the API. Please respond with 'API working'.",
            },
          ],
          max_tokens: 10,
        });

        if (completion.choices[0]?.message?.content) {
          return { status: "âœ…", message: "OpenAI API working correctly" };
        } else {
          return {
            status: "âŒ",
            message: "OpenAI API returned unexpected response",
          };
        }
      } catch (error) {
        if (error.code === "invalid_api_key") {
          return { status: "âŒ", message: "Invalid OpenAI API key" };
        }
        return { status: "âŒ", message: `OpenAI API error: ${error.message}` };
      }
    },
  },

  {
    step: "7. Extracted Data",
    description: "Check if any data has been extracted by OpenAI",
    async check() {
      try {
        const { data, error } = await supabaseAdmin
          .from("scraping_queue")
          .select("*")
          .not("extracted_data", "is", null);

        if (error) {
          return {
            status: "âŒ",
            message: `Extracted data check failed: ${error.message}`,
          };
        }

        if (!data || data.length === 0) {
          return {
            status: "âš ï¸",
            message: "No extracted data found - need to run extraction",
          };
        }

        return {
          status: "âœ…",
          message: `${data.length} URLs have extracted data`,
        };
      } catch (error) {
        return {
          status: "âŒ",
          message: `Extracted data check error: ${error.message}`,
        };
      }
    },
  },

  {
    step: "8. Venues Created",
    description: "Check if venues have been created in the database",
    async check() {
      try {
        const { data, error } = await supabaseAdmin.from("venues").select("*");

        if (error) {
          return {
            status: "âŒ",
            message: `Venues check failed: ${error.message}`,
          };
        }

        if (!data || data.length === 0) {
          return {
            status: "âš ï¸",
            message: "No venues found - extraction may have failed",
          };
        }

        return {
          status: "âœ…",
          message: `${data.length} venues created successfully`,
        };
      } catch (error) {
        return {
          status: "âŒ",
          message: `Venues check error: ${error.message}`,
        };
      }
    },
  },

  {
    step: "9. Packages Created",
    description: "Check if party packages have been created",
    async check() {
      try {
        const { data, error } = await supabaseAdmin
          .from("packages")
          .select("*");

        if (error) {
          return {
            status: "âŒ",
            message: `Packages check failed: ${error.message}`,
          };
        }

        if (!data || data.length === 0) {
          return {
            status: "âš ï¸",
            message: "No packages found - extraction may be incomplete",
          };
        }

        return {
          status: "âœ…",
          message: `${data.length} packages created successfully`,
        };
      } catch (error) {
        return {
          status: "âŒ",
          message: `Packages check error: ${error.message}`,
        };
      }
    },
  },
];

async function runChecklist() {
  console.log("ðŸ” Party Venue App - Pipeline Checklist");
  console.log("==========================================\n");

  const results = [];

  for (const item of checklist) {
    console.log(`Checking: ${item.step} - ${item.description}`);

    try {
      const result = await item.check();
      console.log(`${result.status} ${result.message}\n`);
      results.push({ ...item, ...result });
    } catch (error) {
      console.log(`âŒ Unexpected error: ${error.message}\n`);
      results.push({
        ...item,
        status: "âŒ",
        message: `Unexpected error: ${error.message}`,
      });
    }
  }

  // Summary
  console.log("ðŸ“Š SUMMARY");
  console.log("==========");

  const passed = results.filter((r) => r.status === "âœ…").length;
  const warnings = results.filter((r) => r.status === "âš ï¸").length;
  const failed = results.filter((r) => r.status === "âŒ").length;

  console.log(`âœ… Passed: ${passed}`);
  console.log(`âš ï¸  Warnings: ${warnings}`);
  console.log(`âŒ Failed: ${failed}`);

  // Next steps recommendations
  console.log("\nðŸš€ NEXT STEPS");
  console.log("=============");

  const failedItems = results.filter((r) => r.status === "âŒ");
  const warningItems = results.filter((r) => r.status === "âš ï¸");

  if (failedItems.length > 0) {
    console.log("âŒ Fix these critical issues first:");
    failedItems.forEach((item) => {
      console.log(`   - ${item.step}: ${item.message}`);
    });
  }

  if (warningItems.length > 0 && failedItems.length === 0) {
    console.log("âš ï¸  Address these warnings:");
    warningItems.forEach((item) => {
      console.log(`   - ${item.step}: ${item.message}`);
    });

    // Specific next step recommendations
    if (warningItems.some((item) => item.step.includes("URLs in Queue"))) {
      console.log("\nðŸ’¡ To add URLs:");
      console.log("   npm run scrape:urls  # Collect URLs from DuckDuckGo");
      console.log("   # OR manually add URLs to scraping_queue table");
    }

    if (warningItems.some((item) => item.step.includes("Scraped Data"))) {
      console.log("\nðŸ’¡ To scrape venues:");
      console.log("   npm run scrape:venues");
    }

    if (warningItems.some((item) => item.step.includes("Extracted Data"))) {
      console.log("\nðŸ’¡ To extract data:");
      console.log("   npm run scrape:extract");
    }
  }

  if (passed === checklist.length) {
    console.log("ðŸŽ‰ All checks passed! Pipeline is fully operational.");
    console.log("ðŸ’¡ View results at: http://localhost:3000/admin");
  }
}

runChecklist().catch(console.error);
